[{"id":0,"href":"/docs/trade-days/09-05-24/","title":"09 May, 2024","section":"Docs","content":"My setup worked twice today but I did not trade it. I think I chickened out because I was not sure for some reason idk why but yes I did not follow my rules today. In the later second half, out of fomo I tried to ride the wave but got caught right on the reversal and had to book a big loss. My few days win streak ended just because of my immaturity and carelessness. A little disappointed but tomorrow we will do better.\n"},{"id":1,"href":"/docs/tech/controlling/","title":"Controlling temp, top_p and top_k","section":"Tech","content":" Controlling temp, top_p and top_k # So I have been working on a TTS model and for the last few days I am playing with few hyperparameters. In my specific use case, I found that temperature, top_p and top_k played a major role in audio generated.\ntemperature # helps control the randomness / creativity of the model. Basically you adjust the probabilities to force randomness or determinism. During training the temperature is 1. Mathematically, when the probability of next token is being calculated the model will divide that by your temperature value.\nPython function of softmax with temperature :\ndef softmax_with_temperature(logits, temperature=1.0): logits /= temperature exp_logits = np.exp(logits - np.max(logits)) # subtracting max for numerical stability softmax_output = exp_logits / np.sum(exp_logits) return softmax_output top_p # topp selects most likely token from a prob distribution, considering cumulative probability until it reaches a predefined threshold _p. In other words, only consider the possibilities that equal or exceed this value. Value of this parameter ranges from 0.0 to 1.0\ntop_k # this selects k most likely options (depending on their probabilities). So token with very low probability are not selected which makes output more coherent. I have found that changing top_p and temp is more useful than trying to tweak top_k.\nWhen we set the temperature to 0, choose only the top 1 token (K=1), or the probability threshold to 0 (P=0), it\u0026rsquo;s like swapping out the softmax with a simple maximum selection formula. This means we\u0026rsquo;re only focusing on the single most probable next token and ignoring everything else.\n"},{"id":2,"href":"/docs/tech/llm/","title":"LLM","section":"Tech","content":" Controlling top_p, top_k and temp "},{"id":3,"href":"/docs/tradediary/","title":"Trade Diary","section":"Docs","content":" My trading days # I post here only about my NSE index option trades.\nMay 9 "}]